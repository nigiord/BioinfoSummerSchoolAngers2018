{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Loading-data-from-Tara\" data-toc-modified-id=\"Loading-data-from-Tara-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Loading data from Tara</a></span></li><li><span><a href=\"#Spearman-correlation-matrix\" data-toc-modified-id=\"Spearman-correlation-matrix-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Spearman correlation matrix</a></span><ul class=\"toc-item\"><li><span><a href=\"#Filter-the-data\" data-toc-modified-id=\"Filter-the-data-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Filter the data</a></span></li><li><span><a href=\"#Compute-correlation-matrix\" data-toc-modified-id=\"Compute-correlation-matrix-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Compute correlation matrix</a></span></li><li><span><a href=\"#Clustering\" data-toc-modified-id=\"Clustering-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Clustering</a></span></li></ul></li><li><span><a href=\"#Microbial-ecological-network-inference\" data-toc-modified-id=\"Microbial-ecological-network-inference-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Microbial ecological network inference</a></span><ul class=\"toc-item\"><li><span><a href=\"#Loading-the-necessary-R-packages\" data-toc-modified-id=\"Loading-the-necessary-R-packages-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Loading the necessary R packages</a></span></li><li><span><a href=\"#Convert-the-data-object\" data-toc-modified-id=\"Convert-the-data-object-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Convert the data object</a></span></li><li><span><a href=\"#Filtering\" data-toc-modified-id=\"Filtering-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Filtering</a></span></li><li><span><a href=\"#Running-SPIEC-EASI-on-the-dataset\" data-toc-modified-id=\"Running-SPIEC-EASI-on-the-dataset-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Running SPIEC-EASI on the dataset</a></span></li><li><span><a href=\"#Graphs-visualizations\" data-toc-modified-id=\"Graphs-visualizations-4.5\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>Graphs visualizations</a></span></li><li><span><a href=\"#Exercice\" data-toc-modified-id=\"Exercice-4.6\"><span class=\"toc-item-num\">4.6&nbsp;&nbsp;</span>Exercice</a></span></li></ul></li><li><span><a href=\"#Biclustering-of-the-dataset\" data-toc-modified-id=\"Biclustering-of-the-dataset-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Biclustering of the dataset</a></span><ul class=\"toc-item\"><li><span><a href=\"#Normalization\" data-toc-modified-id=\"Normalization-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Normalization</a></span></li><li><span><a href=\"#Filtering\" data-toc-modified-id=\"Filtering-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Filtering</a></span></li><li><span><a href=\"#Biclustering-on-ISA\" data-toc-modified-id=\"Biclustering-on-ISA-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Biclustering on ISA</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authors: [Samuel Chaffron](https://www.ls2n.fr/annuaire/Samuel%20CHAFFRON)\n",
    "and [Nils Giordano](https://www.ls2n.fr/annuaire/Nils%20GIORDANO)\n",
    "\n",
    "With credits to Marko Budinich, Erwan Delage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this practical exercice, we will use publicly available data from the Tara Oceans project to identify clusters of microorganisms in the global ocean.\n",
    "\n",
    "Data are from this [Ocean-Microbiome EMBL website](http://ocean-microbiome.embl.de/companion.html), which is a *companion* website for the publication:\n",
    ">[Structure and function of the global ocean microbiome](www.sciencemag.org/content/348/6237/1261359.long)  \n",
    "Sunagawa, Coelho, Chaffron, et al., Science, 2015\n",
    "\n",
    "In particular, we will use the Tara miTAGs 16S data (OTUs and taxonomy files, already downloaded for this session)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tool: Jupyter Notebook**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This document is called a [Jupyter Notebook](http://jupyter.org/).\n",
    "> The Jupyter Notebook is an open-source web application that allows you to create and share documents that contain live code, equations, visualizations and narrative text. Uses include: data cleaning and transformation, numerical simulation, statistical modeling, data visualization, machine learning, and much more.\n",
    "\n",
    "Jupyter Notebooks are widely used in Data Science and are compatible with many langages (Julia, Python, R, C++...). Here we will exclusively use the R programming language.\n",
    "\n",
    "Jupyter Notebooks are made of *cells* of text or code that you can edit and execute at will. All the variables are stored in background and shared between cells. Click on the code cell below and press `<SHIFT> + <RETURN>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Hello World!\"\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello World!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are able to access this notebook online thanks to [mybinder](https://mybinder.org/), which associates [JupyterHub](https://jupyterhub.readthedocs.io/en/latest/) and [Docker](https://www.docker.com/) to create interactive instances of a notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data from Tara"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The miTAGs 16S OTUs and taxonomy data have already been formatted in tables by the publication authors. You can find them in the `Data/` folder:\n",
    "\n",
    "- OTU table: `miTAG.taxonomic.profiles.release.OTUtable.tsv`\n",
    "- TAX table: `miTAG.taxonomic.profiles.release.TAXtable.tsv`\n",
    "\n",
    "The code below read these files and load them into R table objects (run it with `<SHIFT> + <RETURN>`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = 'Data/'\n",
    "\n",
    "# Load abundance matrix\n",
    "otumat = read.csv(paste(DIR,\"miTAG.taxonomic.profiles.release.OTUtable.tsv\",sep=\"\"),\n",
    "                  sep=\"\\t\", row.names=1, check.names=FALSE)\n",
    "taxmat = read.csv(paste(DIR,\"miTAG.taxonomic.profiles.release.TAXtable.tsv\",sep=\"\"),\n",
    "                  sep=\"\\t\", row.names=1, check.names=FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can interactively look at the content of the `otumat` and `taxmat` variables simply by typing their names in a R shell.\n",
    "\n",
    "**Q: Look at both tables by editing and executing the code cell below. What are the rows and columns?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENTER IN THIS CELL THE NAME OF THE VARIABLE YOU WANT TO DISPLAY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In what follows we will use these two tables to:\n",
    "- create a correlation matrix of species abundances around the global ocean\n",
    "- infer and display a network of association between species using SPIEC-EASI\n",
    "- compute display (bi-)clusters of association\n",
    "\n",
    "This is 3 different ways to look at microorganism organization. Each part are independent and provide different information on the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spearman correlation matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using the R function `dim()` you can obtain the size of a R object. Note that you can look at the documentation of any R function by executing `?function` in a code cell.\n",
    "\n",
    "**Q: How much Tara samples and OTUs do we have in the `otumat` table?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, most of the OTU are either hardly detectable or only present in a small fraction of the samples. To simplify the analysis, it is common practice to filter out these OTU from our dataset.\n",
    "\n",
    "This is performed by the code cell below.\n",
    "\n",
    "**Q: What kind of filtering is performed by the code below? What are the tresholds? How much did we reduce the size of the dataset?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OTUs as columns\n",
    "totus = t(otumat)\n",
    "\n",
    "# function to perform pre-filtering on OTU with low abundance relative to total abundance\n",
    "# OTUS with an abundance lower than 0.01% of total abundance are removed from the table\n",
    "low.count.removal = function(\n",
    "  data, # OTU count data frame of size n (sample) x p (OTU)\n",
    "  percent=0.01 # cutoff chosen\n",
    "){\n",
    "  keep.otu = which(colSums(data)*100/(sum(colSums(data))) > percent)\n",
    "  data.filter = data[,keep.otu]\n",
    "  return(list(data.filter = data.filter, keep.otu = keep.otu))\n",
    "}\n",
    "\n",
    "# function to perform pre-filtering on OTU with low presence across stations\n",
    "# OTUS that appears in less than 5% of stations are removed from the table\n",
    "min.stations.removal = function(\n",
    "  data, # OTU count data frame of size n (sample) x p (OTU)\n",
    "  percent=0.05 # cutoff chosen\n",
    "){\n",
    "  keep.otu = which(colSums(data != 0) > percent * dim(data)[1])\n",
    "  data.filter = data[,keep.otu]\n",
    "  return(list(data.filter = data.filter, keep.otu = keep.otu))\n",
    "}\n",
    "\n",
    "\n",
    "# Initialize thresholds (in %)\n",
    "thresholdAbundance = 0.1\n",
    "thresholdPresence = 0.6\n",
    "\n",
    "# Remove OTUs with relative abundance lower than 0.1% of total abundance\n",
    "cat(\"NB stations :\",dim(totus)[1],\"\\n\")\n",
    "cat(\"NB otus before abundance filter :\",dim(totus)[2],\"\\n\")\n",
    "nbOtusInitial = dim(totus)[2]\n",
    "\n",
    "ftr = low.count.removal(totus, thresholdAbundance)\n",
    "totus = totus[,ftr$keep.otu]\n",
    "nbOtusAfterAbFilter = dim(totus)[2]\n",
    "cat(\"NB otus after abundance filter :\",nbOtusAfterAbFilter,\"\\n\")\n",
    "\n",
    "# Filter OTU's on presence in minimum number of stations\n",
    "ftr = min.stations.removal(totus,thresholdPresence)\n",
    "totus = totus[,ftr$keep.otu]\n",
    "nbOtusAfterPrFilter = dim(totus)[2]\n",
    "cat(\"NB otus after presence filter :\",nbOtusAfterPrFilter,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute correlation matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are there species for which the abundance accross the samples correlate?\n",
    "\n",
    "We can have a quick glance by simply computing the correlation matrix of our dataset.\n",
    "\n",
    "**Q: Use the function `cor()` of R to plot the correlation matrix  of the `totus` object. Store the result in a variable `cormat` and display it. What are the rows and columns of the matrix? What can you observe on the diagonal?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "## COMPUTE AND PLOT HERE THE CORRELATION MATRIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The matrix can also be visualized using the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ggplot)\n",
    "\n",
    "ggplot(data = cormat, aes(x=OTUs, y=OTUs, fill=value)) + \n",
    "  geom_tile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: Look at the documentation of the `cor()` function. What is the default method used?**  \n",
    "**Q: Reproduce the correlation with the `spearman` method. Compare.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## REPRODUCE THE CORRELATION ANALYSIS WITH THE SPEARMAN METHOD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are computing thousands of correlations (200x200), there is a high probability we observe correlations that are just due to chance (i.e. that are not statistically significant).\n",
    "\n",
    "The `cor()` function does not return the p-value of the correlation. We need for this to load an extra package, `Hmisc`, that provides the `rcorr()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(Hmisc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: Use the `rcorr()` function with the `spearman` method on our dataset and store the result into a `cormat2` variable. What does the `cormat2` object contains?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "## REPRODUCE THE CORRELATION ANALYSIS WITH RCORR()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to extract the p-values or the correlation coefficients from the `cormat2`object, use this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the correlation coefficients\n",
    "cormat2$r\n",
    "# Extract p-values\n",
    "cormat2$P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: Find a way to visualize the matrix of p-values. Are most correlations significant?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "## VISUALIZE THE P-VALUE MATRIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, one could use the p-value matrix to filter out correlations that are not significant (not done here)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plotted 1-vs-1 correlation matrixes, so we are able to see if two OTUs are associated in the dataset. What we actually would like to see is if groups of OTUs occupy the same ecological niche. For this, we can use clustering techniques that will automatically compute a correlation matrix and organize it by groups.\n",
    "\n",
    "For instance, we can use the `heatmap.2()` function from the `gplots` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(gplots)\n",
    "\n",
    "heatmap.2(matrix, hclustfun=function(c) hclust(c, method=\"ward\"),\n",
    "          trace=\"none\", cexRow=.5, cexCol=.5, margins=c(10,15),\n",
    "          col=rev(heat.colors(length(colnames(matrix)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: Comment on the heatmap generate.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Microbial ecological network inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More complex methods exist to infer ecological association between OTUs, and new ones are constantly developed by the research community. Here we will use the method SPIEC-EASI, published in *Plos Computational Biology* in 2015.\n",
    "> SPIEC-EASI (SParse InversE Covariance Estimation for Ecological Association\n",
    "Inference) exploits the fact that under certain assumptions (that all relevant\n",
    "variables are being considered and the data are multivariate normally\n",
    "distributed), the inverse covariance matrix corresponds to a network without\n",
    "indirect edges. SPIEC-EASI estimates the inverse covariance\n",
    "matrix from sequencing data. The inference of networks using the inverse\n",
    "covariance matrix is also known in the literature as Graphical Gaussian model\n",
    "and the inverse covariance matrix is also referred to as precision or partial\n",
    "correlation matrix. SPIEC-EASI is implemented in R, for further details about\n",
    "SPIEC-EASI, please check the associated publication:\n",
    "http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1004226\n",
    "\n",
    "Conveniently, the authors made a R package available on [Github](https://github.com/zdk123/SpiecEasi) for the community.\n",
    ">This package will be useful to anybody who wants to infer graphical models for all sorts of compositional data, though primarily intended for microbiome relative abundance data (generated from 16S amplicon sequence data). It also includes a generator for [overdispersed, zero inflated] multivariate, correlated count data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the necessary R packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPIEC-EASI R package installation (https://github.com/zdk123/SpiecEasi)\n",
    "library(devtools)\n",
    "library(huge)\n",
    "#install_github(\"zdk123/SpiecEasi\")\n",
    "library(SpiecEasi)\n",
    "# Phyloseq installation\n",
    "library(gtools)\n",
    "#source('http://bioconductor.org/biocLite.R')\n",
    "#biocLite('phyloseq')\n",
    "library(phyloseq)\n",
    "# iGraph installation\n",
    "library(Matrix)\n",
    "library(igraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the data object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by converting the data table into objects that can be manipulated by the SpiecEasi package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in otu_table(otumat, taxa_are_rows = TRUE): impossible de trouver la fonction \"otu_table\"\n",
     "output_type": "error",
     "traceback": [
      "Error in otu_table(otumat, taxa_are_rows = TRUE): impossible de trouver la fonction \"otu_table\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "otus = otu_table(otumat, taxa_are_rows = TRUE)\n",
    "taxa = tax_table(as.matrix(taxmat))\n",
    "mat = phyloseq(otus, taxa)\n",
    "\n",
    "# OTUs as columns\n",
    "totus = t(otus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: What contains the `otus` and `taxa` variables? What is the `mat` variable? What is the role of the function `t()`?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "## USE THIS CELL TO OBSERVE THE OBJECTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As above, we will filter OTUs based on their abundance in the dataset. Just run the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to perform pre-filtering on OTU with low abundance relative to total abundance\n",
    "# OTUS with an abundance lower than 0.01% of total abundance are removed from the table\n",
    "low.count.removal = function(\n",
    "  data, # OTU count data frame of size n (sample) x p (OTU)\n",
    "  percent=0.01 # cutoff chosen\n",
    "){\n",
    "  keep.otu = which(colSums(data)*100/(sum(colSums(data))) > percent)\n",
    "  data.filter = data[,keep.otu]\n",
    "  return(list(data.filter = data.filter, keep.otu = keep.otu))\n",
    "}\n",
    "\n",
    "# function to perform pre-filtering on OTU with low presence across stations\n",
    "# OTUS that appears in less than 5% of stations are removed from the table\n",
    "min.stations.removal = function(\n",
    "  data, # OTU count data frame of size n (sample) x p (OTU)\n",
    "  percent=0.05 # cutoff chosen\n",
    "){\n",
    "  keep.otu = which(colSums(data != 0) > percent * dim(data)[1])\n",
    "  data.filter = data[,keep.otu]\n",
    "  return(list(data.filter = data.filter, keep.otu = keep.otu))\n",
    "}\n",
    "\n",
    "\n",
    "# Initialize thresholds (in %)\n",
    "thresholdAbundance = 0.1\n",
    "thresholdPresence = 0.6\n",
    "\n",
    "# Remove OTUs with relative abundance lower than 0.1% of total abundance\n",
    "cat(\"NB stations :\",dim(totus)[1],\"\\n\")\n",
    "cat(\"NB otus before abundance filter :\",dim(totus)[2],\"\\n\")\n",
    "nbOtusInitial = dim(totus)[2]\n",
    "\n",
    "ftr = low.count.removal(totus, thresholdAbundance)\n",
    "totus = totus[,ftr$keep.otu]\n",
    "nbOtusAfterAbFilter = dim(totus)[2]\n",
    "cat(\"NB otus after abundance filter :\",nbOtusAfterAbFilter,\"\\n\")\n",
    "\n",
    "# Filter OTU's on presence in minimum number of stations\n",
    "ftr = min.stations.removal(totus,thresholdPresence)\n",
    "totus = totus[,ftr$keep.otu]\n",
    "nbOtusAfterPrFilter = dim(totus)[2]\n",
    "cat(\"NB otus after presence filter :\",nbOtusAfterPrFilter,\"\\n\")\n",
    "\n",
    "# update phyloseq object after filtering\n",
    "otus = otu_table(totus, taxa_are_rows = F)\n",
    "taxa = tax_table(as.matrix(taxa[colnames(otus),]))\n",
    "physeqo = phyloseq(t(otus), taxa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running SPIEC-EASI on the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simplify this practical exercice, we will use the default parameters. In general, it is good practice to have a look at the documentation and the original publication to adjust the parameters to your problem of interest.\n",
    "\n",
    "The example below does not cover all possible options and parameters. For\n",
    "example, other generative network models are available, the lambda.min.ratio\n",
    "(the scaling factor that determines the minimum sparsity/lambda parameter)\n",
    "shown here might not be right for your dataset. Additionally, increasing the\n",
    "rep.num argument (the number of StARS subsamples) may result in better performance.\n",
    "\n",
    "You can get an idea of the level of customisation that is possible by displaying the `spiec.easi()` documentation using `?spiec.easi`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPIEC-EASI default parameters\n",
    "lambda.min.ratio = 1e-2\n",
    "nlambda = 20\n",
    "\n",
    "# SPIEC-EASI run\n",
    "physeqo.mb = spiec.easi(physeqo, method='mb', lambda.min.ratio=lambda.min.ratio, nlambda=nlambda)\n",
    "print(physeqo.mb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step, we build an iGraph object. We extract the regression coefficients from the SPIEC-EASI\n",
    "output, which for method `mb` is achieved with command `getOptBeta()`.\n",
    "The regression coefficient matrix is not symmetric and can be symmetrised with\n",
    "command `symBeta()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj   = physeqo.mb\n",
    "adj.g = adj2igraph(symBeta(getOptBeta(adj), mode='maxabs'), vertex.attr=list(name=taxa_names(physeqo)))\n",
    "hist(E(adj.g)$weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphs visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should now be able to display the associations that we have just infered using SPIEC-EASI.\n",
    "\n",
    "They are several way of visualization, simply using iGraph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using iGraph\n",
    "## set size of vertex proportional to clr-mean\n",
    "vsize <- rowMeans(clr(otus, 1))+3\n",
    "## set layout\n",
    "am.coord <- layout_with_graphopt(adj.g)\n",
    "plot(adj.g, layout=am.coord, vertex.size=vsize, vertex.label=NA, vertex.color=\"aquamarine2\", edge.color=\"black\", edge.width=E(adj.g)$weight, main=\"Tara euphotic network\")\n",
    "# degree stats\n",
    "dd.mb <- degree.distribution(adj.g)\n",
    "plot(0:(length(dd.mb)-1), dd.mb, ylim=c(0,.35), type='b',\n",
    "     ylab=\"Frequency\", xlab=\"Degree\", main=\"Degree Distributions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... or using physeq:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using phyloseq\n",
    "#pdf(paste(DIR,\"SPIEC-EASI.networks.pdf\",sep=\"\"), paper = \"a4r\", width=29, height=21)\n",
    "plot_network(adj.g, taxa, type='taxa', color=\"Genus\", label=NULL)\n",
    "plot_network(adj.g, taxa, type='taxa', color=\"Class\", label=NULL)\n",
    "plot_network(adj.g, taxa, type='taxa', color=\"Phylum\", label=NULL)\n",
    "#dev.off()\n",
    "\n",
    "# Export graph\n",
    "#write_graph(adj.g, paste(DIR,\"Tara.SUR.DCM.genus.merged16S.graphml\",sep=\"\"), format=\"graphml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: Comment on the graph created. Can you observe some associations?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice\n",
    "\n",
    "Extract the number of positive and negative associations inferred by SPIEC-EASI.\n",
    "\n",
    "They can be obtained from the matrix of regression coefficients stored in the adjancency matrix (adj.g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biclustering of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw earlier that we can observe clusters of correlations between the OTUs. More advances techniques allow to clusterize the data set for rows (samples) and OTUs (columns) at the same time, a technique called [biclustering](https://en.wikipedia.org/wiki/Biclustering)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(biclust) #from CRAN\n",
    "library(isa2) #from CRAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most clustering techniques require the data to be normalized (either by row, column, or both). This can be done easily in R by computing the sum of each row and dividing the whole matrix by the vector obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_reads <- apply(otumat,2,sum)\n",
    "norm_read <- t(t(otumat) / total_reads) #Normalize by total reads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen earlier, we will filter out data that are below a given abundance threshold.\n",
    "\n",
    "**Q: What are the thresholds used in the code below?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "112"
      ],
      "text/latex": [
       "112"
      ],
      "text/markdown": [
       "112"
      ],
      "text/plain": [
       "[1] 112"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "norm_read_filtered <- norm_read \n",
    "\n",
    "# Put 0 where the abundance is below 0.1%\n",
    "norm_read_filtered[norm_read <= 0.001] <- 0 \n",
    "\n",
    "# Conserve only OTUs that appear in at least 60% of the samples\n",
    "mask_rows <- apply(norm_read_filtered > 0,1,sum) >= 0.6*dim(norm_read)[2] \n",
    "norm_read_filtered <- norm_read_filtered[mask_rows,]\n",
    "otus_name_filtered <- data_otusn[mask_rows]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: What is the size of the dataset before and after filtering? How much OTUs did we filter out?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DISPLAY THE SIZE OF THE DATASET BEFORE AND AFTER FILTRATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: Visualize the dataset as in section 3. What \"OTUs\" seem to be overly abundant?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZE THE DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biclustering on ISA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In what follows, we realize a biclustering using the `isa()` method. This can be done simply with default parameters by running the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run ISA with default parameters\n",
    "bic <- isa(as.matrix(norm_read_filtered))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, a lot of things are contained into the `isa()` function. For instance, the method starts to re-normalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a list with two matrices, the first one is transposed\n",
    "isa_norm <- isa.normalize(norm_read_filtered) \n",
    "image(t(isa_norm$Ec),xaxt='n',yaxt='n',xlab=\"Stations\",ylab=\"OTUs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: Compare this matrix with `norm_read_filtered` (displayed earlier). What difference can you observe?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `bic` variable generated by `isa()` contains two matrices which encode the biclusters: one for the OTUs, and one for Tara samples. Each of these matrixes contains biclusters on the columns and the variable of interest (OTUs or Samples) on rows. A non-zero value indicate that the OTU/Sample is part of the indicated bicluster.\n",
    "\n",
    "**Q: How many biclusters are present in the `bic` variable?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DISPLAY THE NUMBER OF BICLUSTERS IN BIC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just have to use the information stored into `bic` to reorder the data in order to make a given bicluster appear in the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For the bicluster 1:\n",
    "n_bic <- 1 # Change hear and repeat for the remaining 9 biclusters\n",
    "rows_bic <- bic$rows[,n_bic] > 0 # select the rows\n",
    "cols_bic <- bic$columns[,n_bic] > 0 # select the columns\n",
    "\n",
    "samples_bc <- colnames(data_table)[cols_bic]\n",
    "otus_bc <- otus_name_filtered[rows_bic]\n",
    "samples_bc\n",
    "otus_bc\n",
    "\n",
    "p1 <- rbind(isa_norm$Ec[rows_bic,cols_bic],isa_norm$Ec[!rows_bic,cols_bic])\n",
    "p2 <- rbind(isa_norm$Ec[rows_bic,!cols_bic],isa_norm$Ec[!rows_bic,!cols_bic])\n",
    "reordered_data <- cbind(p1,p2)\n",
    "image(t(reordered_data),xaxt='n',yaxt='n',xlab=\"Stations\",ylab=\"OTUs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: What do you observe? What is different compared with the simple correlation matrix displayed earlier? Where is the bicluster in the matrix?**\n",
    "\n",
    "We can also only keep the data that belongs to the bicluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image(t(isa_norm$Ec[rows_bic,cols_bic]),xaxt='n',yaxt='n',xlab=\"Stations\",ylab=\"OTUs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: Realize the same analysis for each bicluster present by changing the `n_bic` variable. Comment.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End of the practical exercice."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
